# Test programs

## Test answer's accuracy
### Test results
The test results are shown in `backend\app\tests\test_results` folder. There 
are 2 `jsonl` files in the folder:
* `test_reports.jsonl`: stores the result of the testing process in which the 
`test_chatbot_agent` assesses the accuracy of TUM chatbot's answer.
* `chat_history.jsonl`: stores the chat history that the `test_chatbot_agent` 
made with the TUM chatbot while testing. The chat history has more questions 
than the `test_reports.jsonl` because it starts working before the functionality 
to save data to `test_reports_agent` works. We regards all these information as 
valuable, so we save all of that for further investigation.

To analyse the performance of the TUM chatbot, we use `backend\app\tests\test_reports_analysis`. 
This file will count the number of times that TUM chatbot answers correctly, 
and the number of times its answer is wrong. Then it will calculate the accuracy
rate of the model.
### Test methods
We test the accuracy of chatbot's answers by using Google's Agent Development 
Kit (ADK) Agent. We call the agent as `test_chatbot_agent`. The noteworthy 
advantage of Google ADK Agent is that it can automatically select and run 
the functions (`tools`) given to it. The `test_chatbot_agent` has the following 
tools:
* `randomly_select_a_program`: randomly selects a program and returns all the 
program's information.
* `ask_llm_chatbot`: allows entering the prompt in the parameter, queries our 
TUM chatbot with the prompt, and returns the chatbot's answer.
* `save_test_report`: save the json generated by the `test_chatbot_agent` to a 
JSONL file and continuously update the file once the `test_chatbot_agent` call 
this tool.

The agent has the following tasks:
* Given Technical University of Munich (TUM) programs information, generate 
questions to ask the chatbot. The question should be clear enough so that there
is only one correct answer, and should give enough information to avoid any 
confusion for the chatbot.
* Ask our TUM chatbot
* Assess whether the chatbot's answer is correct
* Fill in a json template and save it to the `test_reports.jsonl` file

### Run tests
To run this test program, please follows the following steps:
1. Create `\backend\.env` file. The file should have the following information:
```env
# Application settings
APP_NAME="Voice Assistant Backend"
DEBUG=True

# Google Gemini API configuration
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-1.5-flash

# API authentication
API_KEY=your_secure_api_key_here

# Database configuration
DATABASE_URL=postgresql://username:password@localhost:5432/voice_assistant

# Redis configuration
REDIS_URL=redis://localhost:6379
# Or use separate configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
# Email settings
EMAIL_ADDRESS=the_address_to_send_email_from
EMAIL_PASSWORD=the_api_password_of_the_email
# The address can be the same
DEFAULT_EMAIL_RECIPIENT=the_address_to_receive_email_from
TUITION_EMAIL_RECIPIENT=the_address_to_receive_email_from
APPLICATION_EMAIL_RECIPIENT=the_address_to_receive_email_from
PROGRAM_EMAIL_RECIPIENT=the_address_to_receive_email_from
```
2. Install Dependencies

```bash
# Install dependencies
pip install -r requirements.txt
```

3. Create virtual environment
```bash
python -m venv venv
```
4. Actiate virtual environment
```bash
# On Window
venv\Scripts\activate

# On Linux/macOS
source venv/bin/activate
```
5. Go to `backend` directory
```bash
cd backend
```
6. Run test program:
```bash
python -m app.tests.test_tum_chatbot
```
7. See the results in `backend\app\tests\test_results` folder.
8. Analyse the TUM chatbot performance by running this:
```bash
python -m app.tests.test_reports_analysis
```
It should show the following information in the CLI
```bash
‚úÖ Correct (True) 101
‚ùå Incorrect (False) 5
üìä Total 106
Acucracy rate: 0.9528301886792453%
```