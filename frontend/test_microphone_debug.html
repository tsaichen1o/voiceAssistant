<!DOCTYPE html>
<html>
<head>
    <title>Microphone Debug Test</title>
    <style>
        body { font-family: Arial, sans-serif; padding: 20px; }
        .status { padding: 10px; margin: 10px 0; border-radius: 5px; }
        .success { background-color: #d4edda; color: #155724; }
        .error { background-color: #f8d7da; color: #721c24; }
        .warning { background-color: #fff3cd; color: #856404; }
        button { padding: 10px 20px; margin: 5px; }
    </style>
</head>
<body>
    <h1>ğŸ¤ Microphone Debug Test</h1>
    
    <div id="status"></div>
    
    <button onclick="testMicrophonePermission()">æµ‹è¯•éº¦å…‹é£æƒé™</button>
    <button onclick="testAudioRecording()">æµ‹è¯•éŸ³é¢‘å½•åˆ¶</button>
    <button onclick="stopRecording()">åœæ­¢å½•åˆ¶</button>
    
    <div id="results"></div>
    
    <script>
        let audioContext = null;
        let mediaStream = null;
        let isRecording = false;
        let audioDataCount = 0;
        
        function log(message, type = 'info') {
            const div = document.createElement('div');
            div.className = `status ${type}`;
            div.innerHTML = `[${new Date().toLocaleTimeString()}] ${message}`;
            document.getElementById('results').appendChild(div);
            console.log(message);
        }
        
        async function testMicrophonePermission() {
            log('ğŸ” æ£€æŸ¥éº¦å…‹é£æƒé™...', 'warning');
            
            try {
                // æ£€æŸ¥æµè§ˆå™¨æƒé™API
                if ('permissions' in navigator) {
                    const permission = await navigator.permissions.query({ name: 'microphone' });
                    log(`ğŸ“‹ æƒé™çŠ¶æ€: ${permission.state}`, permission.state === 'granted' ? 'success' : 'error');
                }
                
                // è¯·æ±‚éº¦å…‹é£è®¿é—®
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: { 
                        channelCount: 1,
                        sampleRate: 16000 
                    } 
                });
                
                log('âœ… éº¦å…‹é£æƒé™è·å–æˆåŠŸï¼', 'success');
                log(`ğŸµ éŸ³é¢‘è½¨é“æ•°é‡: ${stream.getAudioTracks().length}`, 'success');
                
                stream.getAudioTracks().forEach(track => {
                    log(`ğŸ“Š éŸ³é¢‘è½¨é“: ${track.label}, çŠ¶æ€: ${track.readyState}`, 'success');
                });
                
                if (mediaStream) {
                    mediaStream.getTracks().forEach(track => track.stop());
                }
                mediaStream = stream;
                
            } catch (error) {
                log(`âŒ éº¦å…‹é£æƒé™é”™è¯¯: ${error.message}`, 'error');
                log(`é”™è¯¯è¯¦æƒ…: ${error.name}`, 'error');
            }
        }
        
        async function testAudioRecording() {
            if (!mediaStream) {
                log('âš ï¸ è¯·å…ˆæµ‹è¯•éº¦å…‹é£æƒé™', 'warning');
                return;
            }
            
            try {
                log('ğŸ¤ å¼€å§‹æµ‹è¯•éŸ³é¢‘å½•åˆ¶...', 'warning');
                audioDataCount = 0;
                
                // åˆ›å»ºAudioContext
                audioContext = new AudioContext({ sampleRate: 16000 });
                log(`ğŸ”§ AudioContextåˆ›å»ºæˆåŠŸï¼Œé‡‡æ ·ç‡: ${audioContext.sampleRate}Hz`, 'success');
                
                // åˆ›å»ºAudioWorkletå¤„ç†å™¨
                const processorCode = `
                    class TestProcessor extends AudioWorkletProcessor {
                        constructor() {
                            super();
                            this.frameCount = 0;
                        }
                        
                        process(inputs, outputs, parameters) {
                            if (inputs.length > 0 && inputs[0].length > 0) {
                                this.frameCount++;
                                
                                // æ¯100å¸§å‘é€ä¸€æ¬¡ç»Ÿè®¡ä¿¡æ¯
                                if (this.frameCount % 100 === 0) {
                                    const inputChannel = inputs[0][0];
                                    const rms = Math.sqrt(inputChannel.reduce((sum, val) => sum + val * val, 0) / inputChannel.length);
                                    this.port.postMessage({
                                        type: 'audio_data',
                                        frameCount: this.frameCount,
                                        dataLength: inputChannel.length,
                                        rms: rms
                                    });
                                }
                            }
                            return true;
                        }
                    }
                    registerProcessor('test-processor', TestProcessor);
                `;
                
                const blob = new Blob([processorCode], { type: 'application/javascript' });
                const workletURL = URL.createObjectURL(blob);
                await audioContext.audioWorklet.addModule(workletURL);
                
                // è¿æ¥éŸ³é¢‘æº
                const source = audioContext.createMediaStreamSource(mediaStream);
                const workletNode = new AudioWorkletNode(audioContext, 'test-processor');
                
                source.connect(workletNode);
                
                // ç›‘å¬éŸ³é¢‘æ•°æ®
                workletNode.port.onmessage = (event) => {
                    if (event.data.type === 'audio_data') {
                        audioDataCount++;
                        log(`ğŸ“Š éŸ³é¢‘æ•°æ® #${audioDataCount}: å¸§æ•°=${event.data.frameCount}, é•¿åº¦=${event.data.dataLength}, RMS=${event.data.rms.toFixed(4)}`, 'success');
                    }
                };
                
                isRecording = true;
                log('âœ… éŸ³é¢‘å½•åˆ¶å¯åŠ¨æˆåŠŸï¼è¯·è¯´è¯æµ‹è¯•...', 'success');
                
                URL.revokeObjectURL(workletURL);
                
            } catch (error) {
                log(`âŒ éŸ³é¢‘å½•åˆ¶é”™è¯¯: ${error.message}`, 'error');
                console.error('Audio recording error:', error);
            }
        }
        
        function stopRecording() {
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
            
            isRecording = false;
            log(`ğŸ›‘ å½•åˆ¶åœæ­¢ã€‚æ€»å…±æ¥æ”¶åˆ° ${audioDataCount} ä¸ªéŸ³é¢‘æ•°æ®åŒ…`, 'warning');
        }
        
        // é¡µé¢åŠ è½½æ—¶æ£€æŸ¥åŸºæœ¬ä¿¡æ¯
        window.onload = function() {
            log('ğŸŒ æµè§ˆå™¨ä¿¡æ¯æ£€æŸ¥...', 'warning');
            log(`User Agent: ${navigator.userAgent}`, 'info');
            log(`æ˜¯å¦æ”¯æŒMediaDevices: ${!!navigator.mediaDevices}`, 'info');
            log(`æ˜¯å¦æ”¯æŒAudioContext: ${!!window.AudioContext}`, 'info');
            log(`æ˜¯å¦æ”¯æŒAudioWorklet: ${!!window.AudioWorklet}`, 'info');
            
            if (!navigator.mediaDevices) {
                log('âŒ æµè§ˆå™¨ä¸æ”¯æŒMediaDevices API', 'error');
            }
            
            if (!window.AudioContext) {
                log('âŒ æµè§ˆå™¨ä¸æ”¯æŒAudioContext', 'error');
            }
        };
    </script>
</body>
</html> 